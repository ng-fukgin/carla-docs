
传感器与数据
======

传感器是从周围环境中检索数据的参与者。 它们对于为驾驶代理创建学习环境至关重要。

本页总结了开始处理传感器所需的一切。 它介绍了可用的类型及其生命周期的分步指南。

*   [**Sensors step-by-step**](https://carla.readthedocs.io/en/latest/core_sensors/#sensors-step-by-step)
    *   [Setting](https://carla.readthedocs.io/en/latest/core_sensors/#setting)
    *   [Spawning](https://carla.readthedocs.io/en/latest/core_sensors/#spawning)
    *   [Listening](https://carla.readthedocs.io/en/latest/core_sensors/#listening)
    *   [Data](https://carla.readthedocs.io/en/latest/core_sensors/#data)
*   [**Types of sensors**](https://carla.readthedocs.io/en/latest/core_sensors/#types-of-sensors)
    *   [Cameras](https://carla.readthedocs.io/en/latest/core_sensors/#cameras)
    *   [Detectors](https://carla.readthedocs.io/en/latest/core_sensors/#detectors)
    *   [Other](https://carla.readthedocs.io/en/latest/core_sensors/#other)
*   [**Sensors reference**](https://carla.readthedocs.io/en/latest/ref_sensors/)

* * *

传感器步骤
-----

carla.Sensor 类定义了一种特殊类型的参与者，能够测量和流式传输数据。

*   这是什么数据？ 根据传感器的类型，它变化很大。 所有类型的数据都继承自通用 carla.SensorData。
*   他们什么时候检索数据？ 在每个模拟步骤或注册某个事件时。 取决于传感器的类型。
*   他们如何检索数据？ 每个传感器都有一个listen() 方法来接收和管理数据。

尽管存在差异，但所有传感器都以相似的方式使用。

### 设置

与其他所有参与者一样，找到蓝图并设置特定属性。 这在处理传感器时至关重要。 它们的属性将决定获得的结果。

以下示例设置仪表板高清摄像头。

    # Find the blueprint of the sensor.
    blueprint = world.get_blueprint_library().find('sensor.camera.rgb')
    # Modify the attributes of the blueprint to set image resolution and field of view.
    blueprint.set_attribute('image_size_x', '1920')
    blueprint.set_attribute('image_size_y', '1080')
    blueprint.set_attribute('fov', '110')
    # Set the time in seconds between sensor captures
    blueprint.set_attribute('sensor_tick', '1.0')

### 生成

attach\_to 和attachment\_type 至关重要。 传感器应该连接到父参与者（通常是车辆）上，以跟随它并收集信息。 附件类型将确定其位置关于所述车辆的更新方式。

*   刚性附件。 运动对其父位置非常严格。 这是从模拟中检索数据的正确附件。
*   弹簧臂附件。 运动很轻松，加速和减速很少。 此附件仅推荐用于录制模拟视频。 移动是平滑的，并且在更新摄像机位置时避免了“跳跃”。

    transform = carla.Transform(carla.Location(x=0.8, z=1.7))
    sensor = world.spawn_actor(blueprint, transform, attach_to=my_vehicle)

### Listening

每个传感器都有一个listen() 方法。 每次传感器检索数据时都会调用它。

参数回调是一个 lambda 函数。 它描述了传感器在检索数据时应该做什么。 这必须将检索的数据作为参数。

    # do_something() will be called each time a new image is generated by the camera.
    sensor.listen(lambda data: do_something(data))
    
    ...
    
    # This collision sensor would print everytime a collision is detected. 
    def callback(event):
        for actor_id in event:
            vehicle = world_ref().get_actor(actor_id)
            print('Vehicle too close: %s' % vehicle.type_id)
    
    sensor02.listen(callback)

### Data

大多数传感器数据对象都具有将信息保存到磁盘的功能。 这将允许它在其他环境中使用。

传感器类型之间的传感器数据差异很大。 但是，它们总是带有一些基本信息的标记。

传感器数据属性

类型

描述

`frame`

int

进行测量时的帧数。

`timestamp`

double

自剧集开始以来以模拟秒为单位的测量时间戳。

`transform`

[carla.Transform](https://carla.readthedocs.io/en/latest/python_api#carlatransform)

测量时传感器的世界参考。

* * *

传感器类型
-----

### 摄像头

从相机的角度拍摄世界。 对于返回 carla.Image 的相机，您可以使用帮助类 carla.ColorConverter 来修改图像以表示不同的信息。

*   检索每个模拟步骤的数据。

传感器

输出

概述

[Depth](https://carla.readthedocs.io/en/latest/ref_sensors/#depth-camera)

[carla.Image](https://carla.readthedocs.io/en/latest/python_api#carlaimage)

在灰度图中渲染视场中元素的深度。

[RGB](https://carla.readthedocs.io/en/latest/ref_sensors/#rgb-camera)

[carla.Image](https://carla.readthedocs.io/en/latest/python_api#carlaimage)

提供对周围环境的清晰视野。 看起来像一张普通的现场照片。

[Optical Flow](https://carla.readthedocs.io/en/latest/ref_sensors/#optical-flow-camera)

[carla.Image](https://carla.readthedocs.io/en/latest/python_api#carlaimage)

渲染来自相机的每个像素的运动。

[Semantic segmentation](https://carla.readthedocs.io/en/latest/ref_sensors/#semantic-segmentation-camera)

[carla.Image](https://carla.readthedocs.io/en/latest/python_api#carlaimage)

根据标签以特定颜色渲染视野中的元素。

[Instance segmentation](https://carla.readthedocs.io/en/latest/ref_sensors/#instance-segmentation-camera)

[carla.Image](https://carla.readthedocs.io/en/latest/python_api#carlaimage)

根据标签和唯一的对象 ID 以特定颜色渲染视野中的元素。

[DVS](https://carla.readthedocs.io/en/latest/ref_sensors/#dvs-camera)

[carla.DVSEventArray](https://carla.readthedocs.io/en/latest/python_api#carladvseventarray)

作为事件流异步测量亮度强度的变化。

* * *

### 检测器

当它们附加到的对象注册特定事件时检索数据。

*   触发时检索数据。

传感器

输出

概述

[Collision](https://carla.readthedocs.io/en/latest/ref_sensors/#collision-detector)

[carla.CollisionEvent](https://carla.readthedocs.io/en/latest/python_api#carlacollisionevent)

检索其父actor和其他actor之间的碰撞。

[Lane invasion](https://carla.readthedocs.io/en/latest/ref_sensors/#lane-invasion-detector)

[carla.LaneInvasionEvent](https://carla.readthedocs.io/en/latest/python_api#carlalaneinvasionevent)

在其父项越过车道标记时注册。

[Obstacle](https://carla.readthedocs.io/en/latest/ref_sensors/#obstacle-detector)

[carla.ObstacleDetectionEvent](https://carla.readthedocs.io/en/latest/python_api#carlaobstacledetectionevent)

检测到其父级之前可能存在的障碍。

### 其它

不同的功能，例如导航、物理属性测量和场景的 2D/3D 点图。

*   检索每个模拟步骤的数据。

传感器

输出

概述

[GNSS](https://carla.readthedocs.io/en/latest/ref_sensors/#gnss-sensor)

[carla.GNSSMeasurement](https://carla.readthedocs.io/en/latest/python_api#carlagnssmeasurement)

检索传感器的地理位置。

[IMU](https://carla.readthedocs.io/en/latest/ref_sensors/#imu-sensor)

[carla.IMUMeasurement](https://carla.readthedocs.io/en/latest/python_api#carlaimumeasurement)

包括加速度计、陀螺仪和指南针。

[LIDAR](https://carla.readthedocs.io/en/latest/ref_sensors/#lidar-sensor)

[carla.LidarMeasurement](https://carla.readthedocs.io/en/latest/python_api#carlalidarmeasurement)

旋转激光雷达。 生成一个 4D 点云，每个点的坐标和强度对周围环境进行建模。

[Radar](https://carla.readthedocs.io/en/latest/ref_sensors/#radar-sensor)

[carla.RadarMeasurement](https://carla.readthedocs.io/en/latest/python_api#carlaradarmeasurement)

2D 点图建模元素在视线内及其与传感器有关的运动。

[RSS](https://carla.readthedocs.io/en/latest/ref_sensors/#rss-sensor)

[carla.RssResponse](https://carla.readthedocs.io/en/latest/python_api#carlarssresponse)

根据安全检查修改应用于车辆的控制器。 此传感器的工作方式与其他传感器不同，并且有专门的 RSS 文档。

[Semantic LIDAR](https://carla.readthedocs.io/en/latest/ref_sensors/#semantic-lidar-sensor)

[carla.SemanticLidarMeasurement](https://carla.readthedocs.io/en/latest/python_api#carlasemanticlidarmeasurement)

旋转激光雷达。 生成具有有关实例和语义分割的额外信息的 3D 点云。


